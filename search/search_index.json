{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Aurae Aurae is a free and open source Rust project which houses a memory-safe systems runtime daemon built specifically for enterprise distributed systems called auraed . The auraed daemon can be run as a pid 1 on a Linux kernel and manages containers, virtual machines, and spawning short-lived nested virtual instances of itself for an additional layer of isolation. Mission Aurae is on a mission to be the most loved and effective way of managing workloads on a single piece of hardware. Our hope is that by bringing a better set of controls to a node, we can unlock brilliant higher order distributed systems in the future. Aurae takes ownership of all runtime processes on a single piece of hardware, and provides mTLS encrypted gRPC APIs ( Aurae Standard Library ) to manage the processes. With Aurae Cells the project offers a way to slice up a system using various isolation strategies for enterprise workloads. Project Status The project is very young and under active development. The APIs are subject to change without notice until further notice. As we continue to develop the project the APIs will stabilize and eventually a long term stable release will be offered. At this time the project should not be run in production. Please read getting involved if you are interested in joining the project in its early phases. Contribution types of all types and ranges are welcome. You do not have to know Rust to join the project. Runtime Workloads Aurae offers a runtime API which is capable of managing: Executables (Basic runtime processes) Cells (Processes running in a shared cgroup namespace) Spawned Aurae Instances (Short lived nested virtual instances of Aurae) Pods (Cells running in spawned instances) Virtual Machines (Long-lived arbitrary virtual machines) Auraed Think of auraed as a pid 1 init machine daemon with a scope similar to systemd and functionality similar to containerd and firecracker . Authentication Aurae brings SPIFFE / SPIRE (x509 mTLS) backed identity, authentication (authn) and authorization (authz) as low as the Unix domain socket layer in a distributed system. Standard Library Aurae exposes its functionality over a gRPC API which is referred to as the Aurae Standard Library . Principle of Least Awareness A single Aurae instance has no awareness of higher order scheduling mechanisms such as the Kubernetes control plane. Aurae is designed to take ownership of a single node, and expose the standard library as a generic and meaningful way for higher order consumers. Aurae is a low level building block and is designed to work well with any higher order system by offering a thoughtful set of APIs and controls for managing workloads on a node. Motivation Read Why fix Kubernetes and Systemd by Kris N\u00f3va . Aurae attempts to simplify and improve the stack in enterprise distributed systems by carving out a small portion of responsibility while offering a few basic guarantees with regard to state, synchronicity, awareness, and security. Aurae brings enterprise identity as low as the socket layer in a system, which unlocks multi tenant workloads that run below tools like Kubernetes. AuraeScript Aurae offers a Turing complete scripting language built on top of TypeScript called AuraeScript . AuraeScript embeds the Deno source code directly, and offers a remote client and SDK to interface directly with Aurae remotely. The AuraeScript library is automatically generated from the .proto files defined in the Aurae Standard Library . Valid TypeScript files can be leveraged to replace static manifests, as well as interact directly with a running system. #!/usr/bin/env auraescript let cells = new runtime . CellServiceClient (); let allocated = await cells . allocate ( < runtime . AllocateCellRequest > { cell : runtime.Cell.fromPartial ({ name : \"my-cell\" , cpus : \"2\" }) }); let started = await cells . start ( < runtime . StartExecutableRequest > { executable : runtime.Executable.fromPartial ({ cellName : \"my-cell\" , command : \"sleep 4000\" , description : \"Sleep for 4000 seconds\" , name : \"sleep-4000\" }) }) The Aurae Standard Library The Aurae Standard Library is expressed in .proto files and stored in this repository. Many components of the Aurae runtime system are automatically generated from this core definitions. See the V0 API Reference for the current library definition.","title":"Home"},{"location":"#aurae","text":"Aurae is a free and open source Rust project which houses a memory-safe systems runtime daemon built specifically for enterprise distributed systems called auraed . The auraed daemon can be run as a pid 1 on a Linux kernel and manages containers, virtual machines, and spawning short-lived nested virtual instances of itself for an additional layer of isolation.","title":"Aurae"},{"location":"#mission","text":"Aurae is on a mission to be the most loved and effective way of managing workloads on a single piece of hardware. Our hope is that by bringing a better set of controls to a node, we can unlock brilliant higher order distributed systems in the future. Aurae takes ownership of all runtime processes on a single piece of hardware, and provides mTLS encrypted gRPC APIs ( Aurae Standard Library ) to manage the processes. With Aurae Cells the project offers a way to slice up a system using various isolation strategies for enterprise workloads.","title":"Mission"},{"location":"#project-status","text":"The project is very young and under active development. The APIs are subject to change without notice until further notice. As we continue to develop the project the APIs will stabilize and eventually a long term stable release will be offered. At this time the project should not be run in production. Please read getting involved if you are interested in joining the project in its early phases. Contribution types of all types and ranges are welcome. You do not have to know Rust to join the project.","title":"Project Status"},{"location":"#runtime-workloads","text":"Aurae offers a runtime API which is capable of managing: Executables (Basic runtime processes) Cells (Processes running in a shared cgroup namespace) Spawned Aurae Instances (Short lived nested virtual instances of Aurae) Pods (Cells running in spawned instances) Virtual Machines (Long-lived arbitrary virtual machines)","title":"Runtime Workloads"},{"location":"#auraed","text":"Think of auraed as a pid 1 init machine daemon with a scope similar to systemd and functionality similar to containerd and firecracker .","title":"Auraed"},{"location":"#authentication","text":"Aurae brings SPIFFE / SPIRE (x509 mTLS) backed identity, authentication (authn) and authorization (authz) as low as the Unix domain socket layer in a distributed system.","title":"Authentication"},{"location":"#standard-library","text":"Aurae exposes its functionality over a gRPC API which is referred to as the Aurae Standard Library .","title":"Standard Library"},{"location":"#principle-of-least-awareness","text":"A single Aurae instance has no awareness of higher order scheduling mechanisms such as the Kubernetes control plane. Aurae is designed to take ownership of a single node, and expose the standard library as a generic and meaningful way for higher order consumers. Aurae is a low level building block and is designed to work well with any higher order system by offering a thoughtful set of APIs and controls for managing workloads on a node.","title":"Principle of Least Awareness"},{"location":"#motivation","text":"Read Why fix Kubernetes and Systemd by Kris N\u00f3va . Aurae attempts to simplify and improve the stack in enterprise distributed systems by carving out a small portion of responsibility while offering a few basic guarantees with regard to state, synchronicity, awareness, and security. Aurae brings enterprise identity as low as the socket layer in a system, which unlocks multi tenant workloads that run below tools like Kubernetes.","title":"Motivation"},{"location":"#auraescript","text":"Aurae offers a Turing complete scripting language built on top of TypeScript called AuraeScript . AuraeScript embeds the Deno source code directly, and offers a remote client and SDK to interface directly with Aurae remotely. The AuraeScript library is automatically generated from the .proto files defined in the Aurae Standard Library . Valid TypeScript files can be leveraged to replace static manifests, as well as interact directly with a running system. #!/usr/bin/env auraescript let cells = new runtime . CellServiceClient (); let allocated = await cells . allocate ( < runtime . AllocateCellRequest > { cell : runtime.Cell.fromPartial ({ name : \"my-cell\" , cpus : \"2\" }) }); let started = await cells . start ( < runtime . StartExecutableRequest > { executable : runtime.Executable.fromPartial ({ cellName : \"my-cell\" , command : \"sleep 4000\" , description : \"Sleep for 4000 seconds\" , name : \"sleep-4000\" }) })","title":"AuraeScript"},{"location":"#the-aurae-standard-library","text":"The Aurae Standard Library is expressed in .proto files and stored in this repository. Many components of the Aurae runtime system are automatically generated from this core definitions. See the V0 API Reference for the current library definition.","title":"The Aurae Standard Library"},{"location":"build/","text":"Building Aurae from Source Checkout the core aurae repository. Note : Aurae currently only has support for Linux on X86 architecture. https://github.com/aurae-runtime/aurae.git Dependencies The Aurae environment depends on the protoc protocol buffer compiler being available within the path. Install protoc using your operating system's package manager (Or from source if you want to :) ) A few crates are dependent on system libraries such as D-Bus for systemd and seccomp. Ubuntu sudo apt install -y protobuf-compiler pkg-config libdbus-1-dev libseccomp-dev Arch Linux pacman -S protobuf pkgconf dbus libseccomp Prepare the Environment First you will need to create authentication certificates and create an ~/.aurae/config file. make pki config # For quick-start only Now you can compile and install the toolchain make You can optionally compile each submodule directly. make auraed # compile and install auraed with cargo make auraescript # compile and install auraescript with cargo","title":"Building Aurae from Source"},{"location":"build/#building-aurae-from-source","text":"Checkout the core aurae repository. Note : Aurae currently only has support for Linux on X86 architecture. https://github.com/aurae-runtime/aurae.git","title":"Building Aurae from Source"},{"location":"build/#dependencies","text":"The Aurae environment depends on the protoc protocol buffer compiler being available within the path. Install protoc using your operating system's package manager (Or from source if you want to :) ) A few crates are dependent on system libraries such as D-Bus for systemd and seccomp.","title":"Dependencies"},{"location":"build/#ubuntu","text":"sudo apt install -y protobuf-compiler pkg-config libdbus-1-dev libseccomp-dev","title":"Ubuntu"},{"location":"build/#arch-linux","text":"pacman -S protobuf pkgconf dbus libseccomp","title":"Arch Linux"},{"location":"build/#prepare-the-environment","text":"First you will need to create authentication certificates and create an ~/.aurae/config file. make pki config # For quick-start only Now you can compile and install the toolchain make You can optionally compile each submodule directly. make auraed # compile and install auraed with cargo make auraescript # compile and install auraescript with cargo","title":"Prepare the Environment"},{"location":"certs/","text":"Generating Client Certificate Material For an easy start for managing certificate material you can leverage the convenient make target. make pki config Which uses the scripts in /hack to self sign X509 certificates with mock identities. Creating Clients After the initial PKI has been generated using the above make pki command, clients can easily be created using the following. ./hack/certgen-client <name> Where <name> is a unique string for your client you wish to provide authentication material for.","title":"Generating Client Certificate Material"},{"location":"certs/#generating-client-certificate-material","text":"For an easy start for managing certificate material you can leverage the convenient make target. make pki config Which uses the scripts in /hack to self sign X509 certificates with mock identities.","title":"Generating Client Certificate Material"},{"location":"certs/#creating-clients","text":"After the initial PKI has been generated using the above make pki command, clients can easily be created using the following. ./hack/certgen-client <name> Where <name> is a unique string for your client you wish to provide authentication material for.","title":"Creating Clients"},{"location":"contributors/","text":"How to Contribute The following sections cover some ways to contribute to the project. How can I contribute support? How can I contribute code? Read the Code of Conduct . Read the Contribution Guidelines . Sign the CLA to begin contributing as an individual contributor. You're also encouraged to join the Aurae Runtime Discord .","title":"How to Contribute"},{"location":"contributors/#how-to-contribute","text":"The following sections cover some ways to contribute to the project.","title":"How to Contribute"},{"location":"contributors/#how-can-i-contribute-support","text":"","title":"How can I contribute support?"},{"location":"contributors/#how-can-i-contribute-code","text":"Read the Code of Conduct . Read the Contribution Guidelines . Sign the CLA to begin contributing as an individual contributor. You're also encouraged to join the Aurae Runtime Discord .","title":"How can I contribute code?"},{"location":"quickstart/","text":"Aurae Quickstart Now that you have built Aurae from source you can begin using Aurae. Running the Daemon Aurae will run on any system, even if systemd or another init daemon is currently active. sudo -E auraed Writing your first AuraeScript First create an executable script anywhere you like. touch ~/hello.aurae chmod +x ~/hello.aurae Next add the following content. #!/usr/bin/env auraescript let aurae = connect (); aurae . info (). json (); exec ( \"echo 'Hello World!'\" ). json (); You can now run your first AuraeScript. ~/hello.aurae Your output should be in valid JSON which should look similar to the following: { \"subject_common_name\" : \"nova.unsafe.aurae.io\" , \"issuer_common_name\" : \"unsafe.aurae.io\" , \"sha256_fingerprint\" : \"SHA256:7afa7cbf54dacf8368fd7407039594264c5bb22eaa7f8de5017af53f5ab240b0\" , \"key_algorithm\" : \"RSA\" } { \"meta\" : { \"name\" : \"echo 'Hello World!'\" , \"message\" : \"-\" }, \"proc\" : { \"pid\" : 1428 }, \"status\" : 6 , \"stdout\" : \"'Hello World!'\\n\" , \"stderr\" : \"\" , \"exit_code\" : \"exit status: 0\" } As long as the .json() method is used for output, aurae scripts can be piped to jq for easy usage. ~/hello.aurae | jq -r .stdout","title":"Aurae Quickstart"},{"location":"quickstart/#aurae-quickstart","text":"Now that you have built Aurae from source you can begin using Aurae.","title":"Aurae Quickstart"},{"location":"quickstart/#running-the-daemon","text":"Aurae will run on any system, even if systemd or another init daemon is currently active. sudo -E auraed","title":"Running the Daemon"},{"location":"quickstart/#writing-your-first-auraescript","text":"First create an executable script anywhere you like. touch ~/hello.aurae chmod +x ~/hello.aurae Next add the following content. #!/usr/bin/env auraescript let aurae = connect (); aurae . info (). json (); exec ( \"echo 'Hello World!'\" ). json (); You can now run your first AuraeScript. ~/hello.aurae Your output should be in valid JSON which should look similar to the following: { \"subject_common_name\" : \"nova.unsafe.aurae.io\" , \"issuer_common_name\" : \"unsafe.aurae.io\" , \"sha256_fingerprint\" : \"SHA256:7afa7cbf54dacf8368fd7407039594264c5bb22eaa7f8de5017af53f5ab240b0\" , \"key_algorithm\" : \"RSA\" } { \"meta\" : { \"name\" : \"echo 'Hello World!'\" , \"message\" : \"-\" }, \"proc\" : { \"pid\" : 1428 }, \"status\" : 6 , \"stdout\" : \"'Hello World!'\\n\" , \"stderr\" : \"\" , \"exit_code\" : \"exit status: 0\" } As long as the .json() method is used for output, aurae scripts can be piped to jq for easy usage. ~/hello.aurae | jq -r .stdout","title":"Writing your first AuraeScript"},{"location":"auraed/","text":"Aurae Daemon The Aurae Daemon (auraed) is the main daemon that powers Aurae. The Aurae Daemon runs as a gRPC server which listens over a unix domain socket by default. /var/run/aurae/aurae.sock Running Auraed Running as /init is currently under active development. To run auraed as a standard library server you can run the daemon alongside your current init system. sudo -E auraed Additional flags are listed below. USAGE: auraed [OPTIONS] OPTIONS: --ca-crt <CA_CRT> [default: /etc/aurae/pki/ca.crt] -h, --help Print help information -s, --socket <SOCKET> [default: /var/run/aurae/aurae.sock] --server-crt <SERVER_CRT> [default: /etc/aurae/pki/_signed.server.crt] --server-key <SERVER_KEY> [default: /etc/aurae/pki/server.key] -v, --verbose -V, --version Print version information Building from source We suggest using the aurae repository for building all parts of the project. If you intend on building this repository directly you can leverage the Makefile in this repository. make or using Cargo directly cargo clippy cargo install --debug --path .","title":"Aurae Daemon"},{"location":"auraed/#aurae-daemon","text":"The Aurae Daemon (auraed) is the main daemon that powers Aurae. The Aurae Daemon runs as a gRPC server which listens over a unix domain socket by default. /var/run/aurae/aurae.sock","title":"Aurae Daemon"},{"location":"auraed/#running-auraed","text":"Running as /init is currently under active development. To run auraed as a standard library server you can run the daemon alongside your current init system. sudo -E auraed Additional flags are listed below. USAGE: auraed [OPTIONS] OPTIONS: --ca-crt <CA_CRT> [default: /etc/aurae/pki/ca.crt] -h, --help Print help information -s, --socket <SOCKET> [default: /var/run/aurae/aurae.sock] --server-crt <SERVER_CRT> [default: /etc/aurae/pki/_signed.server.crt] --server-key <SERVER_KEY> [default: /etc/aurae/pki/server.key] -v, --verbose -V, --version Print version information","title":"Running Auraed"},{"location":"auraed/#building-from-source","text":"We suggest using the aurae repository for building all parts of the project. If you intend on building this repository directly you can leverage the Makefile in this repository. make or using Cargo directly cargo clippy cargo install --debug --path .","title":"Building from source"},{"location":"auraed/philosophy/","text":"Aurae Daemon Philosophy","title":"Aurae Daemon Philosophy"},{"location":"auraed/philosophy/#aurae-daemon-philosophy","text":"","title":"Aurae Daemon Philosophy"},{"location":"auraescript/","text":"Aurae offers a Turing complete scripting language built on top of TypeScript called AuraeScript . AuraeScript embeds the Deno source code directly, and offers a remote client and SDK to interface directly with Aurae remotely. The AuraeScript library is automatically generated from the .proto files defined in the Aurae Standard Library . Valid TypeScript files can be leveraged to replace static manifests, as well as interact directly with a running system. #!/usr/bin/env auraescript let cells = new runtime . CellServiceClient (); let allocated = await cells . allocate ( < runtime . AllocateCellRequest > { cell : runtime.Cell.fromPartial ({ name : \"my-cell\" , cpus : \"2\" }) }); let started = await cells . start ( < runtime . StartExecutableRequest > { executable : runtime.Executable.fromPartial ({ cellName : \"my-cell\" , command : \"sleep 4000\" , description : \"Sleep for 4000 seconds\" , name : \"sleep-4000\" }) })","title":"Index"},{"location":"blog/2022-10-24-aurae-cells/","text":"Workload Isolation with Aurae Cells Runtime Subsystem Last week we merged Pull Request #73 which marks the project's formal acceptance of our initial runtime subsystem API. service Runtime { rpc RunExecutable ( Executable ) returns ( ExecutableStatus ) {} rpc RunCell ( Cell ) returns ( CellStatus ) {} rpc RunVirtualMachine ( VirtualMachine ) returns ( VirtualMachineStatus ) {} rpc Spawn ( Instance ) returns ( InstanceStatus ) {} rpc RunPod ( Pod ) returns ( PodStatus ) {} } The runtime subsystem is the most fundamental API for Aurae. The API is synchronous, and is intended to serve as the lowest level building block for future subsystems in the project. The API introduces 5 workloads types of runtime isolation primitives, as well as a special function known as Spawn() . The 5 workload types: Executable Cell VirtualMachine Instance Pod Thank you to the many authors, contributors, and maintainers who helped the project form conviction on the initial API: Dominic Hamon | @future-highway | Hazel Weakly | Josh Grant | Malte Janduda | @taniwha3 | Vincent Riesop | Keeping Pods Intuitive We make the assumption that most Aurae consumers will be interested in \"scheduling pods\", as this is the primary unit of work for Kubernetes. Therefore, we knew we wanted to make Pods look and feel as much like Kubernetes as possible, so they would be intuitive for users. From a client perspective an Aurae pod should look, feel, and behave just like an OCI compliant Kubernetes pod with only a few small differences. Aurae pods will run with an extra layer of isolation. This isolation is based on virtualization (when applicable) and resembles how Kata containers are created or how firecracker creates a jailed isolation zone . How Aurae manages and builds this isolation zone for pods is what has influenced the runtime API that you see above. Back to the Basics: cgroups and namespaces In order to understand the 5 workload types we need a small lesson in cgroups and namespaces. Control Groups (cgroups) A control group or \"cgroup\" for short is a way of \"slicing\" a part of a Linux system into smaller units which can be used for whatever you want. For example, you can cordon off 10% of your systems compute and memory resources with a cgroup, and run any process you want inside it. If your workload eats up more than 10% of the allocated resources, the kernel will terminate it. This cgroup behavior is likely the root cause of many of the OOMKilled and CPU throttling errors you see in Kubernetes today. Notably there are 2 types of cgroup implementation : v1 and v2. Aurae will use the v2 standard by default. Namespaces A namespace is a way of sharing or isolating specific parts of a Linux system with a process. If all namespaces are shared a process is as close as possible to the \"host\" it runs on. If no namespaces are shared a process is as isolated as possible from the \"host\" it runs on. Exposing namespaces is usually how container escapes are performed, and how lower level networking and storage is managed with Kubernetes. [ root@alice ] : ls /proc/1/ns cgroup ipc mnt net pid pid_for_children time time_for_children user uts Containers I often say that cgroups are \"vertical\" resource slices and namespaces are \"horizontal\" access controls. When a cgroup is run in its own namespaces it's both a slice of resources, and an isolation boundary as well. We call this intersection a \"container\". Systemd Slices By default, systemd schedules all of its workloads in their own cgroup with access to the same namespaces as pid 1 on the system. These workloads are called services or units. Interestingly enough, Kubernetes also leverages systemd slices. You can usually see both systemd slices ( system.slice ) and Kubernetes pods ( kubepods.slice ) running side-by-side by exploring /sys or sysfs(5) on your system. There are usually other cgroups running there as well. [ root@alice ] : /sys/fs/cgroup># ls -d */ dev-hugepages.mount// kubepods.slice// sys-kernel-config.mount// system.slice// dev-mqueue.mount// pids// sys-kernel-debug.mount// user.slice// init.scope// sys-fs-fuse-connections.mount// sys-kernel-tracing.mount// Simplifying the Stack We know we wanted to simplify how workloads are managed at scale. We believe that standardizing process management and cgroup management is a way to simplify runtime complexity, as well as offer a means to an ends with the noisy neighbor problem in multi tenant systems. Therefore, we knew we wanted Aurae to offer functionality that would allow it to manage cgroups well for a plethora of runtime use cases and not just containers. In Kubernetes a user needs to understand the nuance of cgroup implementation detail, systemd scheduling semantics, systemd cgroup drivers, 1 of many container runtimes, CNI, CSI, and more in order to cordon off and network a section of their system. With Aurae a user only needs awareness of a single binary which will safely do all of the above in a secure way by default. Introducing Aurae Cells An Aurae Cell is just a group of processes running in a unique cgroup with explicit deny-by-default access to host namespaces. Additionally, the processes running in a cell will share namespaces, which mirrors how Kubernetes runs containers in a pod. This implies that processes will be able to communicate over the Linux loopback interface (localhost), and share storage between them. These processes can be grouped together and executed beside each other. Most users will recognize this pattern as the pattern that has enabled the sidecar pattern . Because Aurae intends to manage every process on a system, Aurae will be able to make trustworthy guarantees and offer expressive controls over how a host is broken into cells. Executables Aurae will be able to execute regular old shell processes in a cell. We call these each of these basic processes an Executable . rpc RunExecutable ( Executable ) returns ( ExecutableStatus ) {} Container Cells Additionally, Aurae will be able to execute OCI compliant container images in a cell which we just call a Cell . rpc RunCell ( Cell ) returns ( CellStatus ) {} Regardless of if an administrator is executing a basic process, or a container: Aurae will manage the underlying cgroup and namespace implementation. Introducing Virtualization Taking a step back from containerization we also understand that many enterprise users will need to execute untrusted code at scale. Aurae additionally acts as a lightweight virtualization hypervisor and meta-data service in addition to being a cgroup broker. Each instance of Aurae comes with its own running pid 1 daemon called auraed . Understanding Virtualization Virtualization is a more secure level of isolation that operates closer to the hardware. The boundary between a host and a guest virtualized workload is layer 3 of networking, and block patterns in storage. This more abstract interface creates a much more resilient environment for executing a workload. rpc RunVirtualMachine ( VirtualMachine ) returns ( VirtualMachineStatus ) {} MicroVMs with Aurae Aurae brings the short-lived, destroy on exit (MicroVM) paradigm into scope by embedding the firecracker Rust crates directly and scheduling workloads with the KVM or Kernel-based Virtual Machine. Aurae is able to Spawn() a new Instance of itself into a newly created MicroVM which can be used arbitrarily. Aurae Spawn The name Spawn() is taken from the Rust std::process crate and resembles a pattern what most Linux users will know as unshare(2) or namespace delegation. Basically a spawned instance of Aurae will inherit certain properties from the parent, and will come with a few basic guarantees with regard to security and connectivity. Aurae is designed to be recursive, which enables nested isolation zones and gives the project the basic building blocks it needs to hold an opinion on how users should run workloads. Spawned Aurae instances will receive a bridged TAP network device which a nested auraed daemon will listen on by default. This allows a parent Aurae instance running with an independent kernel to communicate directly with a child instance over the same mTLS authenticated gRPC API the rest of the project leverages. rpc Spawn ( Instance ) returns ( InstanceStatus ) {} Aurae will manage creating an ephemeral SPIFFE service identity for each spawned instance and will delegate down kernel images, initramfs , and even the auraed daemon itself. Aurae manages the Spawn() including the networking bridge, and service identity management transparently at runtime. Note : In the case that virtualization is not available on the host (e.g. nested virtualization in the cloud), Aurae will spawn directly into an isolated Cell. Virtual Machines with Aurae Because Aurae will have the capability to Spawn() itself using the KVM, it is also possible to expose raw virtual machine functionality for users who wish to leverage Aurae as a long-lived hypervisor as well. Because Aurae maintains its own concept of system state as well as all of the cells on a system it is possible to break up a single host in many ways, with many isolation possibilities. rpc RunVirtualMachine ( VirtualMachine ) returns ( VirtualMachineStatus ) {} Pods Finally, we have the vocabulary needed to explain how an Aurae pod is unique. An Aurae pod is a Cell running in a spawned Aurae Instance . rpc RunPod ( Pod ) returns ( PodStatus ) {} First Aurae will spawn a new instance of itself. Next Aurae will bridge to the spawned instance, and establish connectivity as a client to the new instance. The parent will then run a cell in the newly spawned Aurae instance. Because Aurae is acts as a hypervisor this gives an operator the ability to mount network devices directly into the spawned instance, which can be referenced from the nested cell. We believe this pattern to be a more flexible, secure, and efficient pattern which can be leveraged in place of traditional sidecar style mesh networking that is often seen with service mesh projects such as Istio . From the original client's perspective scheduling a pod will feel natural, and will still expose basic fields such as OCI image, listen port, etc. Users can run a pod with Aurae, and the extra isolation layer should be transparent and free just by executing the RunPod gRPC function. Note : The project has decided not to support the Kubernetes Pod API directly at this layer of the stack. What's Next? The project is under active development, and many of the features described in this blog are currently a work in progress. If you are interested in helping us work on these features please feel welcome to join the discord where we discuss our progress. If you are interested in contributing please see the getting involved documentation. If you are interested in finding areas to contribute please see our good first issues which are designed to be easy for a newcomer to pick up and get started with. f you are interested in discussing product opportunities, or venture funding we unfortunately are not taking these discussions at this time. Our intention is to keep Aurae free and community driven. Author: Kris N\u00f3va","title":"Workload Isolation with Aurae Cells"},{"location":"blog/2022-10-24-aurae-cells/#workload-isolation-with-aurae-cells","text":"","title":"Workload Isolation with Aurae Cells"},{"location":"blog/2022-10-24-aurae-cells/#runtime-subsystem","text":"Last week we merged Pull Request #73 which marks the project's formal acceptance of our initial runtime subsystem API. service Runtime { rpc RunExecutable ( Executable ) returns ( ExecutableStatus ) {} rpc RunCell ( Cell ) returns ( CellStatus ) {} rpc RunVirtualMachine ( VirtualMachine ) returns ( VirtualMachineStatus ) {} rpc Spawn ( Instance ) returns ( InstanceStatus ) {} rpc RunPod ( Pod ) returns ( PodStatus ) {} } The runtime subsystem is the most fundamental API for Aurae. The API is synchronous, and is intended to serve as the lowest level building block for future subsystems in the project. The API introduces 5 workloads types of runtime isolation primitives, as well as a special function known as Spawn() . The 5 workload types: Executable Cell VirtualMachine Instance Pod Thank you to the many authors, contributors, and maintainers who helped the project form conviction on the initial API: Dominic Hamon | @future-highway | Hazel Weakly | Josh Grant | Malte Janduda | @taniwha3 | Vincent Riesop |","title":"Runtime Subsystem"},{"location":"blog/2022-10-24-aurae-cells/#keeping-pods-intuitive","text":"We make the assumption that most Aurae consumers will be interested in \"scheduling pods\", as this is the primary unit of work for Kubernetes. Therefore, we knew we wanted to make Pods look and feel as much like Kubernetes as possible, so they would be intuitive for users. From a client perspective an Aurae pod should look, feel, and behave just like an OCI compliant Kubernetes pod with only a few small differences. Aurae pods will run with an extra layer of isolation. This isolation is based on virtualization (when applicable) and resembles how Kata containers are created or how firecracker creates a jailed isolation zone . How Aurae manages and builds this isolation zone for pods is what has influenced the runtime API that you see above.","title":"Keeping Pods Intuitive"},{"location":"blog/2022-10-24-aurae-cells/#back-to-the-basics-cgroups-and-namespaces","text":"In order to understand the 5 workload types we need a small lesson in cgroups and namespaces.","title":"Back to the Basics: cgroups and namespaces"},{"location":"blog/2022-10-24-aurae-cells/#control-groups-cgroups","text":"A control group or \"cgroup\" for short is a way of \"slicing\" a part of a Linux system into smaller units which can be used for whatever you want. For example, you can cordon off 10% of your systems compute and memory resources with a cgroup, and run any process you want inside it. If your workload eats up more than 10% of the allocated resources, the kernel will terminate it. This cgroup behavior is likely the root cause of many of the OOMKilled and CPU throttling errors you see in Kubernetes today. Notably there are 2 types of cgroup implementation : v1 and v2. Aurae will use the v2 standard by default.","title":"Control Groups (cgroups)"},{"location":"blog/2022-10-24-aurae-cells/#namespaces","text":"A namespace is a way of sharing or isolating specific parts of a Linux system with a process. If all namespaces are shared a process is as close as possible to the \"host\" it runs on. If no namespaces are shared a process is as isolated as possible from the \"host\" it runs on. Exposing namespaces is usually how container escapes are performed, and how lower level networking and storage is managed with Kubernetes. [ root@alice ] : ls /proc/1/ns cgroup ipc mnt net pid pid_for_children time time_for_children user uts","title":"Namespaces"},{"location":"blog/2022-10-24-aurae-cells/#containers","text":"I often say that cgroups are \"vertical\" resource slices and namespaces are \"horizontal\" access controls. When a cgroup is run in its own namespaces it's both a slice of resources, and an isolation boundary as well. We call this intersection a \"container\".","title":"Containers"},{"location":"blog/2022-10-24-aurae-cells/#systemd-slices","text":"By default, systemd schedules all of its workloads in their own cgroup with access to the same namespaces as pid 1 on the system. These workloads are called services or units. Interestingly enough, Kubernetes also leverages systemd slices. You can usually see both systemd slices ( system.slice ) and Kubernetes pods ( kubepods.slice ) running side-by-side by exploring /sys or sysfs(5) on your system. There are usually other cgroups running there as well. [ root@alice ] : /sys/fs/cgroup># ls -d */ dev-hugepages.mount// kubepods.slice// sys-kernel-config.mount// system.slice// dev-mqueue.mount// pids// sys-kernel-debug.mount// user.slice// init.scope// sys-fs-fuse-connections.mount// sys-kernel-tracing.mount//","title":"Systemd Slices"},{"location":"blog/2022-10-24-aurae-cells/#simplifying-the-stack","text":"We know we wanted to simplify how workloads are managed at scale. We believe that standardizing process management and cgroup management is a way to simplify runtime complexity, as well as offer a means to an ends with the noisy neighbor problem in multi tenant systems. Therefore, we knew we wanted Aurae to offer functionality that would allow it to manage cgroups well for a plethora of runtime use cases and not just containers. In Kubernetes a user needs to understand the nuance of cgroup implementation detail, systemd scheduling semantics, systemd cgroup drivers, 1 of many container runtimes, CNI, CSI, and more in order to cordon off and network a section of their system. With Aurae a user only needs awareness of a single binary which will safely do all of the above in a secure way by default.","title":"Simplifying the Stack"},{"location":"blog/2022-10-24-aurae-cells/#introducing-aurae-cells","text":"An Aurae Cell is just a group of processes running in a unique cgroup with explicit deny-by-default access to host namespaces. Additionally, the processes running in a cell will share namespaces, which mirrors how Kubernetes runs containers in a pod. This implies that processes will be able to communicate over the Linux loopback interface (localhost), and share storage between them. These processes can be grouped together and executed beside each other. Most users will recognize this pattern as the pattern that has enabled the sidecar pattern . Because Aurae intends to manage every process on a system, Aurae will be able to make trustworthy guarantees and offer expressive controls over how a host is broken into cells.","title":"Introducing Aurae Cells"},{"location":"blog/2022-10-24-aurae-cells/#executables","text":"Aurae will be able to execute regular old shell processes in a cell. We call these each of these basic processes an Executable . rpc RunExecutable ( Executable ) returns ( ExecutableStatus ) {}","title":"Executables"},{"location":"blog/2022-10-24-aurae-cells/#container-cells","text":"Additionally, Aurae will be able to execute OCI compliant container images in a cell which we just call a Cell . rpc RunCell ( Cell ) returns ( CellStatus ) {} Regardless of if an administrator is executing a basic process, or a container: Aurae will manage the underlying cgroup and namespace implementation.","title":"Container Cells"},{"location":"blog/2022-10-24-aurae-cells/#introducing-virtualization","text":"Taking a step back from containerization we also understand that many enterprise users will need to execute untrusted code at scale. Aurae additionally acts as a lightweight virtualization hypervisor and meta-data service in addition to being a cgroup broker. Each instance of Aurae comes with its own running pid 1 daemon called auraed .","title":"Introducing Virtualization"},{"location":"blog/2022-10-24-aurae-cells/#understanding-virtualization","text":"Virtualization is a more secure level of isolation that operates closer to the hardware. The boundary between a host and a guest virtualized workload is layer 3 of networking, and block patterns in storage. This more abstract interface creates a much more resilient environment for executing a workload. rpc RunVirtualMachine ( VirtualMachine ) returns ( VirtualMachineStatus ) {}","title":"Understanding Virtualization"},{"location":"blog/2022-10-24-aurae-cells/#microvms-with-aurae","text":"Aurae brings the short-lived, destroy on exit (MicroVM) paradigm into scope by embedding the firecracker Rust crates directly and scheduling workloads with the KVM or Kernel-based Virtual Machine. Aurae is able to Spawn() a new Instance of itself into a newly created MicroVM which can be used arbitrarily.","title":"MicroVMs with Aurae"},{"location":"blog/2022-10-24-aurae-cells/#aurae-spawn","text":"The name Spawn() is taken from the Rust std::process crate and resembles a pattern what most Linux users will know as unshare(2) or namespace delegation. Basically a spawned instance of Aurae will inherit certain properties from the parent, and will come with a few basic guarantees with regard to security and connectivity. Aurae is designed to be recursive, which enables nested isolation zones and gives the project the basic building blocks it needs to hold an opinion on how users should run workloads. Spawned Aurae instances will receive a bridged TAP network device which a nested auraed daemon will listen on by default. This allows a parent Aurae instance running with an independent kernel to communicate directly with a child instance over the same mTLS authenticated gRPC API the rest of the project leverages. rpc Spawn ( Instance ) returns ( InstanceStatus ) {} Aurae will manage creating an ephemeral SPIFFE service identity for each spawned instance and will delegate down kernel images, initramfs , and even the auraed daemon itself. Aurae manages the Spawn() including the networking bridge, and service identity management transparently at runtime. Note : In the case that virtualization is not available on the host (e.g. nested virtualization in the cloud), Aurae will spawn directly into an isolated Cell.","title":"Aurae Spawn"},{"location":"blog/2022-10-24-aurae-cells/#virtual-machines-with-aurae","text":"Because Aurae will have the capability to Spawn() itself using the KVM, it is also possible to expose raw virtual machine functionality for users who wish to leverage Aurae as a long-lived hypervisor as well. Because Aurae maintains its own concept of system state as well as all of the cells on a system it is possible to break up a single host in many ways, with many isolation possibilities. rpc RunVirtualMachine ( VirtualMachine ) returns ( VirtualMachineStatus ) {}","title":"Virtual Machines with Aurae"},{"location":"blog/2022-10-24-aurae-cells/#pods","text":"Finally, we have the vocabulary needed to explain how an Aurae pod is unique. An Aurae pod is a Cell running in a spawned Aurae Instance . rpc RunPod ( Pod ) returns ( PodStatus ) {} First Aurae will spawn a new instance of itself. Next Aurae will bridge to the spawned instance, and establish connectivity as a client to the new instance. The parent will then run a cell in the newly spawned Aurae instance. Because Aurae is acts as a hypervisor this gives an operator the ability to mount network devices directly into the spawned instance, which can be referenced from the nested cell. We believe this pattern to be a more flexible, secure, and efficient pattern which can be leveraged in place of traditional sidecar style mesh networking that is often seen with service mesh projects such as Istio . From the original client's perspective scheduling a pod will feel natural, and will still expose basic fields such as OCI image, listen port, etc. Users can run a pod with Aurae, and the extra isolation layer should be transparent and free just by executing the RunPod gRPC function. Note : The project has decided not to support the Kubernetes Pod API directly at this layer of the stack.","title":"Pods"},{"location":"blog/2022-10-24-aurae-cells/#whats-next","text":"The project is under active development, and many of the features described in this blog are currently a work in progress. If you are interested in helping us work on these features please feel welcome to join the discord where we discuss our progress. If you are interested in contributing please see the getting involved documentation. If you are interested in finding areas to contribute please see our good first issues which are designed to be easy for a newcomer to pick up and get started with. f you are interested in discussing product opportunities, or venture funding we unfortunately are not taking these discussions at this time. Our intention is to keep Aurae free and community driven. Author: Kris N\u00f3va","title":"What's Next?"},{"location":"blog/2022-12-11-cgroups/","text":"Cgroups in Aurae We need a way to map processes to cgroups or in Aurae parlance executables to cells . Given a cgroup my-cell and two nested processes: sleep 500 with the name sleep-500 sleep 60 with the name sleep-60 How do we identify which PID to send signals to if the user intends to start/stop either the sleep-500 or the sleep-60 process within the cell? Research with Systemd The way systemd manages this is by storing the Unit file contents in memory during the duration of the process. This is why systemd daemon-reload must be executed before changes to the current unit file are effective. The mapping of the configuration in the Unit file to the sub-processes is managed in memory. Differences from Systemd We would like to be able to start and stop arbitrary processes within a given cell. We currently believe that systemd creates a cgroup for each service, and the only way to \"add\" nested processes to a cgroup is by restarting the service with a hook to launch the intended nested process. Option 1) The \"/var/run/aurae/cells\" Way We create a new directory upon starting the daemon called /var/run/aurae/cells that we assume ownership of. We bake in the initialization setup in the same way we manage /var/run/aurae.sock . For every cell that is allocated we also create a file: /var/run/aurae/cells/my-cell We use the pre_exec function to create a file descriptor for each nested process that points back to the cell file. The children will store the file descriptors and not the parent. Author: Kris N\u00f3va","title":"Cgroups in Aurae"},{"location":"blog/2022-12-11-cgroups/#cgroups-in-aurae","text":"We need a way to map processes to cgroups or in Aurae parlance executables to cells . Given a cgroup my-cell and two nested processes: sleep 500 with the name sleep-500 sleep 60 with the name sleep-60 How do we identify which PID to send signals to if the user intends to start/stop either the sleep-500 or the sleep-60 process within the cell?","title":"Cgroups in Aurae"},{"location":"blog/2022-12-11-cgroups/#research-with-systemd","text":"The way systemd manages this is by storing the Unit file contents in memory during the duration of the process. This is why systemd daemon-reload must be executed before changes to the current unit file are effective. The mapping of the configuration in the Unit file to the sub-processes is managed in memory.","title":"Research with Systemd"},{"location":"blog/2022-12-11-cgroups/#differences-from-systemd","text":"We would like to be able to start and stop arbitrary processes within a given cell. We currently believe that systemd creates a cgroup for each service, and the only way to \"add\" nested processes to a cgroup is by restarting the service with a hook to launch the intended nested process.","title":"Differences from Systemd"},{"location":"blog/2022-12-11-cgroups/#option-1-the-varrunauraecells-way","text":"We create a new directory upon starting the daemon called /var/run/aurae/cells that we assume ownership of. We bake in the initialization setup in the same way we manage /var/run/aurae.sock . For every cell that is allocated we also create a file: /var/run/aurae/cells/my-cell We use the pre_exec function to create a file descriptor for each nested process that points back to the cell file. The children will store the file descriptors and not the parent. Author: Kris N\u00f3va","title":"Option 1) The \"/var/run/aurae/cells\" Way"},{"location":"crate/SourceSerif4-LICENSE/","text":"Copyright 2014-2021 Adobe (http://www.adobe.com/), with Reserved Font Name 'Source'. All Rights Reserved. Source is a trademark of Adobe in the United States and/or other countries. This Font Software is licensed under the SIL Open Font License, Version 1.1. This license is copied below, and is also available with a FAQ at: http://scripts.sil.org/OFL SIL OPEN FONT LICENSE Version 1.1 - 26 February 2007 PREAMBLE The goals of the Open Font License (OFL) are to stimulate worldwide development of collaborative font projects, to support the font creation efforts of academic and linguistic communities, and to provide a free and open framework in which fonts may be shared and improved in partnership with others. The OFL allows the licensed fonts to be used, studied, modified and redistributed freely as long as they are not sold by themselves. The fonts, including any derivative works, can be bundled, embedded, redistributed and/or sold with any software provided that any reserved names are not used by derivative works. The fonts and derivatives, however, cannot be released under any other type of license. The requirement for fonts to remain under this license does not apply to any document created using the fonts or their derivatives. DEFINITIONS \"Font Software\" refers to the set of files released by the Copyright Holder(s) under this license and clearly marked as such. This may include source files, build scripts and documentation. \"Reserved Font Name\" refers to any names specified as such after the copyright statement(s). \"Original Version\" refers to the collection of Font Software components as distributed by the Copyright Holder(s). \"Modified Version\" refers to any derivative made by adding to, deleting, or substituting -- in part or in whole -- any of the components of the Original Version, by changing formats or by porting the Font Software to a new environment. \"Author\" refers to any designer, engineer, programmer, technical writer or other person who contributed to the Font Software. PERMISSION & CONDITIONS Permission is hereby granted, free of charge, to any person obtaining a copy of the Font Software, to use, study, copy, merge, embed, modify, redistribute, and sell modified and unmodified copies of the Font Software, subject to the following conditions: 1) Neither the Font Software nor any of its individual components, in Original or Modified Versions, may be sold by itself. 2) Original or Modified Versions of the Font Software may be bundled, redistributed and/or sold with any software, provided that each copy contains the above copyright notice and this license. These can be included either as stand-alone text files, human-readable headers or in the appropriate machine-readable metadata fields within text or binary files as long as those fields can be easily viewed by the user. 3) No Modified Version of the Font Software may use the Reserved Font Name(s) unless explicit written permission is granted by the corresponding Copyright Holder. This restriction only applies to the primary font name as presented to the users. 4) The name(s) of the Copyright Holder(s) or the Author(s) of the Font Software shall not be used to promote, endorse or advertise any Modified Version, except to acknowledge the contribution(s) of the Copyright Holder(s) and the Author(s) or with their explicit written permission. 5) The Font Software, modified or unmodified, in part or in whole, must be distributed entirely under this license, and must not be distributed under any other license. The requirement for fonts to remain under this license does not apply to any document created using the Font Software. TERMINATION This license becomes null and void if any of the above conditions are not met. DISCLAIMER THE FONT SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM OTHER DEALINGS IN THE FONT SOFTWARE.","title":"SourceSerif4 LICENSE"},{"location":"crate/SourceSerif4-LICENSE/#sil-open-font-license-version-11-26-february-2007","text":"PREAMBLE The goals of the Open Font License (OFL) are to stimulate worldwide development of collaborative font projects, to support the font creation efforts of academic and linguistic communities, and to provide a free and open framework in which fonts may be shared and improved in partnership with others. The OFL allows the licensed fonts to be used, studied, modified and redistributed freely as long as they are not sold by themselves. The fonts, including any derivative works, can be bundled, embedded, redistributed and/or sold with any software provided that any reserved names are not used by derivative works. The fonts and derivatives, however, cannot be released under any other type of license. The requirement for fonts to remain under this license does not apply to any document created using the fonts or their derivatives. DEFINITIONS \"Font Software\" refers to the set of files released by the Copyright Holder(s) under this license and clearly marked as such. This may include source files, build scripts and documentation. \"Reserved Font Name\" refers to any names specified as such after the copyright statement(s). \"Original Version\" refers to the collection of Font Software components as distributed by the Copyright Holder(s). \"Modified Version\" refers to any derivative made by adding to, deleting, or substituting -- in part or in whole -- any of the components of the Original Version, by changing formats or by porting the Font Software to a new environment. \"Author\" refers to any designer, engineer, programmer, technical writer or other person who contributed to the Font Software. PERMISSION & CONDITIONS Permission is hereby granted, free of charge, to any person obtaining a copy of the Font Software, to use, study, copy, merge, embed, modify, redistribute, and sell modified and unmodified copies of the Font Software, subject to the following conditions: 1) Neither the Font Software nor any of its individual components, in Original or Modified Versions, may be sold by itself. 2) Original or Modified Versions of the Font Software may be bundled, redistributed and/or sold with any software, provided that each copy contains the above copyright notice and this license. These can be included either as stand-alone text files, human-readable headers or in the appropriate machine-readable metadata fields within text or binary files as long as those fields can be easily viewed by the user. 3) No Modified Version of the Font Software may use the Reserved Font Name(s) unless explicit written permission is granted by the corresponding Copyright Holder. This restriction only applies to the primary font name as presented to the users. 4) The name(s) of the Copyright Holder(s) or the Author(s) of the Font Software shall not be used to promote, endorse or advertise any Modified Version, except to acknowledge the contribution(s) of the Copyright Holder(s) and the Author(s) or with their explicit written permission. 5) The Font Software, modified or unmodified, in part or in whole, must be distributed entirely under this license, and must not be distributed under any other license. The requirement for fonts to remain under this license does not apply to any document created using the Font Software. TERMINATION This license becomes null and void if any of the above conditions are not met. DISCLAIMER THE FONT SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM OTHER DEALINGS IN THE FONT SOFTWARE.","title":"SIL OPEN FONT LICENSE Version 1.1 - 26 February 2007"},{"location":"stdlib/","text":"The Aurae Standard Library The Aurae Standard Library (stdlib or \"the library\") is a set of remote functions grouped together into logical groups called subsystems. The library leverages protobuf as the source of truth for the types, names, and function signatures for the library. What is a subsystem? A subsystem is a smaller and scoped subsection of the library composed of RPCs and services. Subsystems are similar to \"packages\" or \"modules\" in programming languages such as Rust . Kubernetes as API groups, and Linux itself has subsystems. Each subsystem is unique. Each subsystem is liable to come with its own guarantees, and expectations. In protobuf terms a subsystem is a group of remote procedure calls (RPCs) and services . What are resources? Aurae is built on the concept of core resources that represent the main components of the system. Resources are like objects. For example, Aurae has the concept of an Executable resource which represents an executable workload similar to systemd's Unit . The core resources are intended to be fundamental and composable, similar to the objects and structures found in modern programming languages. Resources are defined directly in the corresponding protobuf definition and later generated into code for various languages. A resource's corresponding message should never be passed to directly to, or received directly from an RPC. In protobuf terms a resource is a message . What are services? Services are a section of the API designed to be a way of grouping functionality together such that it can be enabled/disabled with authorization mechanisms. A service should be discreet in the terms of how it mutates the system. For example if a service starts, it should stop. If a service allocates, it should free. And so on. Services should be named after a resource or set of functionality around common resources. Services should follow the service NameService paradigm as defined in the style guide For example the service that mutates a Cell should be called CellService . What are functions? A function is a discreet piece of functionality designed to execute on the \"backend\", or directly by an Aurae Daemon server. The library is designed to be executed procedurally and quickly. Many function calls per second is a reasonable expectation for any client. In protobuf terms a function is a remote procedure call (RPC) API Definition Convention Generally follow this style guide in the proto files. It is short, but the main points are: Files should be named lower_snake_case.proto Files should be ordered in the following manner // AURAE LICENSE HEADER syntax = \"proto3\" ; package lower_snake_case_package_name ; // imports sorted alphabetically import \"path/to/dependency.proto\" ; import \"path/to/other.proto\" ; // file options // everything else Generally follow these rules: Services should be named UpperCamelCase (aka PascalCase) Service methods should be named UpperCamelCase Messages should be named UpperCamelCase Field names, including oneof and extension names, should be snake_case repeated fields should have pluralized names Enums should be named UpperCamelCase Enum variants should be SCREAMING_SNAKE_CASE (Suggested) The zero value enum variants should have the suffix UNSPECIFIED (Suggested) Enums should NOT be nested, and their variants should be prefixed with the enum's name enum FooBar { FOO_BAR_UNSPECIFIED = 0 ; FOO_BAR_FIRST_VALUE = 1 ; FOO_BAR_SECOND_VALUE = 2 ; } A notable exception to the public specification above is the Aurae projects preference for standardizing the objects that are used as the request and response messages. The traditional convention that is meant to reduce the likelihood of future breaking changes and ease the creation of macros for generating code: rpc methods (e.g., StartWidget ) should have dedicated request and response messages named StartWidgetResponse and StartWidgetResponse objects (e.g., Widget ) should be embedded directly into their corresponding StartWidgetRequest , StopWidgetReqyest , etc style methods.","title":"The Aurae Standard Library"},{"location":"stdlib/#the-aurae-standard-library","text":"The Aurae Standard Library (stdlib or \"the library\") is a set of remote functions grouped together into logical groups called subsystems. The library leverages protobuf as the source of truth for the types, names, and function signatures for the library.","title":"The Aurae Standard Library"},{"location":"stdlib/#what-is-a-subsystem","text":"A subsystem is a smaller and scoped subsection of the library composed of RPCs and services. Subsystems are similar to \"packages\" or \"modules\" in programming languages such as Rust . Kubernetes as API groups, and Linux itself has subsystems. Each subsystem is unique. Each subsystem is liable to come with its own guarantees, and expectations. In protobuf terms a subsystem is a group of remote procedure calls (RPCs) and services .","title":"What is a subsystem?"},{"location":"stdlib/#what-are-resources","text":"Aurae is built on the concept of core resources that represent the main components of the system. Resources are like objects. For example, Aurae has the concept of an Executable resource which represents an executable workload similar to systemd's Unit . The core resources are intended to be fundamental and composable, similar to the objects and structures found in modern programming languages. Resources are defined directly in the corresponding protobuf definition and later generated into code for various languages. A resource's corresponding message should never be passed to directly to, or received directly from an RPC. In protobuf terms a resource is a message .","title":"What are resources?"},{"location":"stdlib/#what-are-services","text":"Services are a section of the API designed to be a way of grouping functionality together such that it can be enabled/disabled with authorization mechanisms. A service should be discreet in the terms of how it mutates the system. For example if a service starts, it should stop. If a service allocates, it should free. And so on. Services should be named after a resource or set of functionality around common resources. Services should follow the service NameService paradigm as defined in the style guide For example the service that mutates a Cell should be called CellService .","title":"What are services?"},{"location":"stdlib/#what-are-functions","text":"A function is a discreet piece of functionality designed to execute on the \"backend\", or directly by an Aurae Daemon server. The library is designed to be executed procedurally and quickly. Many function calls per second is a reasonable expectation for any client. In protobuf terms a function is a remote procedure call (RPC)","title":"What are functions?"},{"location":"stdlib/#api-definition-convention","text":"Generally follow this style guide in the proto files. It is short, but the main points are: Files should be named lower_snake_case.proto Files should be ordered in the following manner // AURAE LICENSE HEADER syntax = \"proto3\" ; package lower_snake_case_package_name ; // imports sorted alphabetically import \"path/to/dependency.proto\" ; import \"path/to/other.proto\" ; // file options // everything else Generally follow these rules: Services should be named UpperCamelCase (aka PascalCase) Service methods should be named UpperCamelCase Messages should be named UpperCamelCase Field names, including oneof and extension names, should be snake_case repeated fields should have pluralized names Enums should be named UpperCamelCase Enum variants should be SCREAMING_SNAKE_CASE (Suggested) The zero value enum variants should have the suffix UNSPECIFIED (Suggested) Enums should NOT be nested, and their variants should be prefixed with the enum's name enum FooBar { FOO_BAR_UNSPECIFIED = 0 ; FOO_BAR_FIRST_VALUE = 1 ; FOO_BAR_SECOND_VALUE = 2 ; } A notable exception to the public specification above is the Aurae projects preference for standardizing the objects that are used as the request and response messages. The traditional convention that is meant to reduce the likelihood of future breaking changes and ease the creation of macros for generating code: rpc methods (e.g., StartWidget ) should have dedicated request and response messages named StartWidgetResponse and StartWidgetResponse objects (e.g., Widget ) should be embedded directly into their corresponding StartWidgetRequest , StopWidgetReqyest , etc style methods.","title":"API Definition Convention"},{"location":"stdlib/v0/","text":"Protocol Documentation Table of Contents observe.proto GetAuraeDaemonLogStreamRequest GetSubProcessStreamRequest LogItem LogChannelType Observe runtime.proto AllocateCellRequest AllocateCellResponse Cell Executable FreeCellRequest FreeCellResponse StartExecutableRequest StartExecutableResponse StopExecutableRequest StopExecutableResponse CellService Instances Pods Spawn schedule.proto Scalar Value Types Top observe.proto GetAuraeDaemonLogStreamRequest GetSubProcessStreamRequest TODO: not implemented Field Type Label Description channel_type LogChannelType process_id int64 LogItem Field Type Label Description channel string line string timestamp int64 LogChannelType Name Number Description CHANNEL_STDOUT 0 CHANNEL_STDERR 1 Observe Method Name Request Type Response Type Description GetAuraeDaemonLogStream GetAuraeDaemonLogStreamRequest LogItem stream request log stream for aurae. everything logged via log macros in aurae (info!, error!, trace!, ... ). GetSubProcessStream GetSubProcessStreamRequest LogItem stream TODO: request log stream for a sub process Top runtime.proto AllocateCellRequest An Aurae cell is a name given to Linux control groups (cgroups) that also include / a name, and special pre-exec functionality that is executed from within the same context / as any executables scheduled. / / A cell must be allocated for every executable scheduled. A cell defines the resource / constraints of the system to allocate for an arbitrary use case. Field Type Label Description cell Cell A smaller resource constrained section of the system. AllocateCellResponse The response after a cell has been allocated. Field Type Label Description cell_name string cgroup_v2 bool A bool that will be set to true if the cgroup was created with / cgroup v2 controller. Cell An isolation resource used to divide a system into smaller resource / boundaries. Field Type Label Description name string Resource parameters for control groups (cgroups) / Build on the cgroups-rs / crate. See / examples cpu_cpus string A comma-separated list of CPU IDs where the task in the control group / can run. Dashes between numbers indicate ranges. cpu_shares uint64 Cgroups can be guaranteed a minimum number of \"CPU shares\" / when a system is busy. This does not limit a cgroup's CPU / usage if the CPUs are not busy. For further information, / see Documentation/scheduler/sched-design-CFS.rst (or / Documentation/scheduler/sched-design-CFS.txt in Linux 5.2 / and earlier). / / Weight of how much of the total CPU time should this control / group get. Note that this is hierarchical, so this is weighted / against the siblings of this control group. cpu_mems string Same syntax as the cpus field of this structure, but applies to / memory nodes instead of processors. cpu_quota int64 In one period, how much can the tasks run in microseconds. ns_share_mount bool Linux namespaces to share with the calling process. / If all values are set to false, the resulting cell / will be as isolated as possible. / / Each shared namespace is a potential security risk. ns_share_uts bool ns_share_ipc bool ns_share_pid bool ns_share_net bool ns_share_cgroup bool Executable The most primitive workload in Aurae, a standard executable process. Field Type Label Description name string command string description string FreeCellRequest Used to remove or free a cell after it has been allocated. Field Type Label Description cell_name string FreeCellResponse Response after removing or freeing a cell. StartExecutableRequest A request for starting an executable inside of a Cell. / / This is the lowest level of raw executive functionality. / Here you can define shell commands, and meta information about the command. / An executable is started synchronously. Field Type Label Description cell_name string executable Executable StartExecutableResponse The response after starting an executable within a Cell. Field Type Label Description pid int32 Return a pid as an int32 based on the pid_t type / in various libc libraries. StopExecutableRequest Field Type Label Description cell_name string executable_name string StopExecutableResponse CellService Cells is the most fundamental isolation boundary for Aurae. / A cell is an isolate set of resources of the system which can be / used to run workloads. / / A cell is composed of a unique cgroup namespace, and unshared kernel / namespaces. Method Name Request Type Response Type Description Allocate AllocateCellRequest AllocateCellResponse Reserve requested system resources for a new cell. / For cells specifically this will allocate and reserve cgroup resources / only. Free FreeCellRequest FreeCellResponse Free up previously requested resources for an existing cell Start StartExecutableRequest StartExecutableResponse Start a new Executable inside of an existing cell. Can be called / in serial to start more than one executable in the same cell. Stop StopExecutableRequest StopExecutableResponse Stop one or more Executables inside of an existing cell. / Can be called in serial to stop/retry more than one executable. Instances TODO Instances Service Method Name Request Type Response Type Description Pods TODO Pods Service Method Name Request Type Response Type Description Spawn TODO Spawn Service Method Name Request Type Response Type Description Top schedule.proto Scalar Value Types .proto Type Notes C++ Java Python Go C# PHP Ruby double double double float float64 double float Float float float float float float32 float float Float int32 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint32 instead. int32 int int int32 int integer Bignum or Fixnum (as required) int64 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint64 instead. int64 long int/long int64 long integer/string Bignum uint32 Uses variable-length encoding. uint32 int int/long uint32 uint integer Bignum or Fixnum (as required) uint64 Uses variable-length encoding. uint64 long int/long uint64 ulong integer/string Bignum or Fixnum (as required) sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int int32 int integer Bignum or Fixnum (as required) sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long int/long int64 long integer/string Bignum fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int int uint32 uint integer Bignum or Fixnum (as required) fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long int/long uint64 ulong integer/string Bignum sfixed32 Always four bytes. int32 int int int32 int integer Bignum or Fixnum (as required) sfixed64 Always eight bytes. int64 long int/long int64 long integer/string Bignum bool bool boolean boolean bool bool boolean TrueClass/FalseClass string A string must always contain UTF-8 encoded or 7-bit ASCII text. string String str/unicode string string string String (UTF-8) bytes May contain any arbitrary sequence of bytes. string ByteString str []byte ByteString string String (ASCII-8BIT)","title":"Protocol Documentation"},{"location":"stdlib/v0/#protocol-documentation","text":"","title":"Protocol Documentation"},{"location":"stdlib/v0/#table-of-contents","text":"observe.proto GetAuraeDaemonLogStreamRequest GetSubProcessStreamRequest LogItem LogChannelType Observe runtime.proto AllocateCellRequest AllocateCellResponse Cell Executable FreeCellRequest FreeCellResponse StartExecutableRequest StartExecutableResponse StopExecutableRequest StopExecutableResponse CellService Instances Pods Spawn schedule.proto Scalar Value Types Top","title":"Table of Contents"},{"location":"stdlib/v0/#observeproto","text":"","title":"observe.proto"},{"location":"stdlib/v0/#getauraedaemonlogstreamrequest","text":"","title":"GetAuraeDaemonLogStreamRequest"},{"location":"stdlib/v0/#getsubprocessstreamrequest","text":"TODO: not implemented Field Type Label Description channel_type LogChannelType process_id int64","title":"GetSubProcessStreamRequest"},{"location":"stdlib/v0/#logitem","text":"Field Type Label Description channel string line string timestamp int64","title":"LogItem"},{"location":"stdlib/v0/#logchanneltype","text":"Name Number Description CHANNEL_STDOUT 0 CHANNEL_STDERR 1","title":"LogChannelType"},{"location":"stdlib/v0/#observe","text":"Method Name Request Type Response Type Description GetAuraeDaemonLogStream GetAuraeDaemonLogStreamRequest LogItem stream request log stream for aurae. everything logged via log macros in aurae (info!, error!, trace!, ... ). GetSubProcessStream GetSubProcessStreamRequest LogItem stream TODO: request log stream for a sub process Top","title":"Observe"},{"location":"stdlib/v0/#runtimeproto","text":"","title":"runtime.proto"},{"location":"stdlib/v0/#allocatecellrequest","text":"An Aurae cell is a name given to Linux control groups (cgroups) that also include / a name, and special pre-exec functionality that is executed from within the same context / as any executables scheduled. / / A cell must be allocated for every executable scheduled. A cell defines the resource / constraints of the system to allocate for an arbitrary use case. Field Type Label Description cell Cell A smaller resource constrained section of the system.","title":"AllocateCellRequest"},{"location":"stdlib/v0/#allocatecellresponse","text":"The response after a cell has been allocated. Field Type Label Description cell_name string cgroup_v2 bool A bool that will be set to true if the cgroup was created with / cgroup v2 controller.","title":"AllocateCellResponse"},{"location":"stdlib/v0/#cell","text":"An isolation resource used to divide a system into smaller resource / boundaries. Field Type Label Description name string Resource parameters for control groups (cgroups) / Build on the cgroups-rs / crate. See / examples cpu_cpus string A comma-separated list of CPU IDs where the task in the control group / can run. Dashes between numbers indicate ranges. cpu_shares uint64 Cgroups can be guaranteed a minimum number of \"CPU shares\" / when a system is busy. This does not limit a cgroup's CPU / usage if the CPUs are not busy. For further information, / see Documentation/scheduler/sched-design-CFS.rst (or / Documentation/scheduler/sched-design-CFS.txt in Linux 5.2 / and earlier). / / Weight of how much of the total CPU time should this control / group get. Note that this is hierarchical, so this is weighted / against the siblings of this control group. cpu_mems string Same syntax as the cpus field of this structure, but applies to / memory nodes instead of processors. cpu_quota int64 In one period, how much can the tasks run in microseconds. ns_share_mount bool Linux namespaces to share with the calling process. / If all values are set to false, the resulting cell / will be as isolated as possible. / / Each shared namespace is a potential security risk. ns_share_uts bool ns_share_ipc bool ns_share_pid bool ns_share_net bool ns_share_cgroup bool","title":"Cell"},{"location":"stdlib/v0/#executable","text":"The most primitive workload in Aurae, a standard executable process. Field Type Label Description name string command string description string","title":"Executable"},{"location":"stdlib/v0/#freecellrequest","text":"Used to remove or free a cell after it has been allocated. Field Type Label Description cell_name string","title":"FreeCellRequest"},{"location":"stdlib/v0/#freecellresponse","text":"Response after removing or freeing a cell.","title":"FreeCellResponse"},{"location":"stdlib/v0/#startexecutablerequest","text":"A request for starting an executable inside of a Cell. / / This is the lowest level of raw executive functionality. / Here you can define shell commands, and meta information about the command. / An executable is started synchronously. Field Type Label Description cell_name string executable Executable","title":"StartExecutableRequest"},{"location":"stdlib/v0/#startexecutableresponse","text":"The response after starting an executable within a Cell. Field Type Label Description pid int32 Return a pid as an int32 based on the pid_t type / in various libc libraries.","title":"StartExecutableResponse"},{"location":"stdlib/v0/#stopexecutablerequest","text":"Field Type Label Description cell_name string executable_name string","title":"StopExecutableRequest"},{"location":"stdlib/v0/#stopexecutableresponse","text":"","title":"StopExecutableResponse"},{"location":"stdlib/v0/#cellservice","text":"Cells is the most fundamental isolation boundary for Aurae. / A cell is an isolate set of resources of the system which can be / used to run workloads. / / A cell is composed of a unique cgroup namespace, and unshared kernel / namespaces. Method Name Request Type Response Type Description Allocate AllocateCellRequest AllocateCellResponse Reserve requested system resources for a new cell. / For cells specifically this will allocate and reserve cgroup resources / only. Free FreeCellRequest FreeCellResponse Free up previously requested resources for an existing cell Start StartExecutableRequest StartExecutableResponse Start a new Executable inside of an existing cell. Can be called / in serial to start more than one executable in the same cell. Stop StopExecutableRequest StopExecutableResponse Stop one or more Executables inside of an existing cell. / Can be called in serial to stop/retry more than one executable.","title":"CellService"},{"location":"stdlib/v0/#instances","text":"TODO Instances Service Method Name Request Type Response Type Description","title":"Instances"},{"location":"stdlib/v0/#pods","text":"TODO Pods Service Method Name Request Type Response Type Description","title":"Pods"},{"location":"stdlib/v0/#spawn","text":"TODO Spawn Service Method Name Request Type Response Type Description Top","title":"Spawn"},{"location":"stdlib/v0/#scheduleproto","text":"","title":"schedule.proto"},{"location":"stdlib/v0/#scalar-value-types","text":".proto Type Notes C++ Java Python Go C# PHP Ruby double double double float float64 double float Float float float float float float32 float float Float int32 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint32 instead. int32 int int int32 int integer Bignum or Fixnum (as required) int64 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint64 instead. int64 long int/long int64 long integer/string Bignum uint32 Uses variable-length encoding. uint32 int int/long uint32 uint integer Bignum or Fixnum (as required) uint64 Uses variable-length encoding. uint64 long int/long uint64 ulong integer/string Bignum or Fixnum (as required) sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int int32 int integer Bignum or Fixnum (as required) sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long int/long int64 long integer/string Bignum fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int int uint32 uint integer Bignum or Fixnum (as required) fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long int/long uint64 ulong integer/string Bignum sfixed32 Always four bytes. int32 int int int32 int integer Bignum or Fixnum (as required) sfixed64 Always eight bytes. int64 long int/long int64 long integer/string Bignum bool bool boolean boolean bool bool boolean TrueClass/FalseClass string A string must always contain UTF-8 encoded or 7-bit ASCII text. string String str/unicode string string string String (UTF-8) bytes May contain any arbitrary sequence of bytes. string ByteString str []byte ByteString string String (ASCII-8BIT)","title":"Scalar Value Types"}]}